{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcv\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import torch\n",
    "import sklearn\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../src\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Label:  bakone Images:  9\n",
      "Label:  bakone Images:  178\n",
      "Validation Label:  salein Images:  8\n",
      "Label:  salein Images:  188\n",
      "Validation Label:  da_ote_chite Images:  8\n",
      "Label:  da_ote_chite Images:  204\n",
      "Validation Label:  na_nge Images:  9\n",
      "Label:  na_nge Images:  207\n",
      "Validation Label:  kagyi Images:  10\n",
      "Label:  kagyi Images:  176\n",
      "Validation Label:  pha_ote_tote Images:  12\n",
      "Label:  pha_ote_tote Images:  169\n",
      "Validation Label:  ta_taa_lin_chate Images:  10\n",
      "Label:  ta_taa_lin_chate Images:  210\n",
      "Validation Label:  ya_kout Images:  9\n",
      "Label:  ya_kout Images:  180\n",
      "Validation Label:  7 Images:  12\n",
      "Label:  7 Images:  194\n"
     ]
    }
   ],
   "source": [
    "class CharData:\n",
    "    i_penetration: np.ndarray\n",
    "    j_penetration: np.ndarray\n",
    "\n",
    "    top_depth: np.ndarray\n",
    "    left_depth: np.ndarray\n",
    "\n",
    "    image_width: int\n",
    "    image_height: int\n",
    "    sample_count: int\n",
    "\n",
    "    # def resample(self, target_samples: int):\n",
    "    #     i_resampled = np.interp(\n",
    "    #         np.linspace(0, len(self.i_penetration) - 1, target_samples),\n",
    "    #         np.arange(len(self.i_penetration)),\n",
    "    #         self.i_penetration,\n",
    "    #     )\n",
    "    #     j_resampled = np.interp(\n",
    "    #         np.linspace(0, len(self.j_penetration) - 1, target_samples),\n",
    "    #         np.arange(len(self.j_penetration)),\n",
    "    #         self.j_penetration,\n",
    "    #     )\n",
    "\n",
    "    #     self.i_penetration = i_resampled\n",
    "    #     self.j_penetration = j_resampled\n",
    "\n",
    "    # Normalize the penetration values to be between 0 and 1\n",
    "    # Adapentive penetration is probably bad because it makes comparisons between characters useless\n",
    "    def normalize(self, i_pen_max, j_pen_max, top_depth_max, left_depth_max, adaptive_pen = False):\n",
    "        if adaptive_pen:\n",
    "            i_pen_max = np.max(self.i_penetration)\n",
    "            j_pen_max = np.max(self.j_penetration)\n",
    "        \n",
    "        self.i_penetration = np.divide(self.i_penetration, i_pen_max)\n",
    "        self.j_penetration = np.divide(self.j_penetration, j_pen_max)\n",
    "        self.top_depth = np.divide(self.top_depth, top_depth_max)\n",
    "        self.left_depth = np.divide(self.left_depth, left_depth_max)\n",
    "\n",
    "    def __init__(self, image: np.ndarray, sample_count: int = 128):\n",
    "        if len(image.shape) == 3:\n",
    "            image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        self.sample_count = sample_count\n",
    "\n",
    "        i_pen = np.zeros(sample_count, dtype=float)\n",
    "        j_pen = np.zeros(sample_count, dtype=float)\n",
    "\n",
    "        top_depth = np.zeros(sample_count, dtype=float)\n",
    "        left_depth = np.zeros(sample_count, dtype=float)\n",
    "\n",
    "        def map_idx(idx: int, sample_count: int, range_top: int) -> int:\n",
    "            return min(\n",
    "                int(idx * (float(range_top) / float(sample_count))), range_top - 1\n",
    "            )\n",
    "\n",
    "        self.image_height = image.shape[0]\n",
    "        self.image_width = image.shape[1]\n",
    "        penetrating_i = False\n",
    "        for i in range(sample_count):\n",
    "            for j in range(sample_count):\n",
    "                if (\n",
    "                    image[\n",
    "                        int(map_idx(j, sample_count, self.image_height)),\n",
    "                        int(map_idx(i, sample_count, self.image_width)),\n",
    "                    ]\n",
    "                    <= 150\n",
    "                ):\n",
    "                    if top_depth[i] == 0:\n",
    "                        top_depth[i] = j\n",
    "                    if not penetrating_i:\n",
    "                        i_pen[i] += 1\n",
    "                        penetrating_i = True\n",
    "                else:\n",
    "                    penetrating_i = False\n",
    "\n",
    "        penetrating_j = False\n",
    "        for j in range(sample_count):\n",
    "            for i in range(sample_count):\n",
    "                if (\n",
    "                    image[\n",
    "                        int(map_idx(j, sample_count, self.image_height)),\n",
    "                        int(map_idx(i, sample_count, self.image_width)),\n",
    "                    ]\n",
    "                    <= 150\n",
    "                ):\n",
    "                    if left_depth[j] == 0:\n",
    "                        left_depth[j] = i\n",
    "                    if not penetrating_j:\n",
    "                        j_pen[j] += 1\n",
    "                        penetrating_j = True\n",
    "                else:\n",
    "                    penetrating_j = False\n",
    "\n",
    "        self.i_penetration = i_pen\n",
    "        self.j_penetration = j_pen\n",
    "\n",
    "        self.top_depth = top_depth\n",
    "        self.left_depth = left_depth\n",
    "\n",
    "\n",
    "# Images are layed out as follows\n",
    "# /data/\n",
    "# /{label}/\n",
    "# {id}(.png/.jpg/.jpeg)\n",
    "\n",
    "\n",
    "class LabelDataCollection:\n",
    "    name: str\n",
    "    images: list[np.ndarray]\n",
    "    char_data: list[CharData]\n",
    "\n",
    "    def __init__(self, name, images):\n",
    "        self.name = name\n",
    "        self.images = images\n",
    "        self.char_data = []\n",
    "        for image in images:\n",
    "            self.char_data.append(CharData(image))\n",
    "\n",
    "        for data in self.char_data:\n",
    "            data.normalize(5, 5, data.sample_count, data.sample_count)\n",
    "\n",
    "\n",
    "label_collections = []\n",
    "\n",
    "validation_label_collections = []\n",
    "\n",
    "for dir in os.listdir(\"./data\"):\n",
    "    if os.path.isdir(os.path.join(\"./data\", dir)):\n",
    "        name = dir\n",
    "        images = []\n",
    "\n",
    "        for file in os.listdir(os.path.join(\"./data\", dir)):\n",
    "            if os.path.isfile(os.path.join(\"./data\", dir, file)):\n",
    "                img = cv.imread(os.path.join(\"./data\", dir, file))\n",
    "                images.append(img)\n",
    "            else:\n",
    "                if file == \"validation\":\n",
    "                    val_images = []\n",
    "                    for file in os.listdir(os.path.join(\"./data\", dir, \"validation\")):\n",
    "                        if os.path.isfile(os.path.join(\"./data\", dir, \"validation\", file)):\n",
    "                            img = cv.imread(os.path.join(\"./data\", dir, \"validation\", file))\n",
    "                            val_images.append(img)\n",
    "                    validation_label_collections.append(LabelDataCollection(name, val_images))\n",
    "                    print(\n",
    "                        \"Validation Label: \",\n",
    "                        validation_label_collections[-1].name,\n",
    "                        \"Images: \",\n",
    "                        len(validation_label_collections[-1].images),\n",
    "                    )\n",
    "        label_collections.append(LabelDataCollection(name, images))\n",
    "        print(\n",
    "        \"Label: \",\n",
    "        label_collections[-1].name,\n",
    "        \"Images: \",\n",
    "        len(label_collections[-1].images),\n",
    "    )\n",
    "\n",
    "# for x in range(len(label_collections)):\n",
    "#     y = 0\n",
    "#     plt.imshow(label_collections[x].images[y])\n",
    "#     plt.title(label_collections[x].name, family=\"Noto Sans Myanmar\", fontsize=72)\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.title(f\"Penetration\")\n",
    "#     plt.plot(label_collections[x].char_data[y].i_penetration, label=\"i_penetration\")\n",
    "#     plt.plot(label_collections[x].char_data[y].j_penetration, label=\"j_penetration\")\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.title(f\"Depth\")\n",
    "#     plt.plot(label_collections[x].char_data[y].top_depth, label=\"top_depth\")\n",
    "#     plt.plot(label_collections[x].char_data[y].left_depth, label=\"left_depth\")\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:  9\n",
      "Input size:  512\n",
      "Hidden size:  350\n",
      "Classes:  [('7', 194), ('bakone', 178), ('da_ote_chite', 204), ('kagyi', 176), ('na_nge', 207), ('pha_ote_tote', 169), ('salein', 188), ('ta_taa_lin_chate', 210), ('ya_kout', 180)]\n",
      "Weights:  [0.97709049255441, 1.0649188514357053, 0.9291938997821351, 1.077020202020202, 0.9157273215244229, 1.121630506245891, 1.008274231678487, 0.9026455026455027, 1.0530864197530865]\n",
      "Epoch [1/8], Loss: 0.8374\n",
      "Epoch [2/8], Loss: 0.4056\n",
      "Epoch [3/8], Loss: 0.278\n",
      "Epoch [4/8], Loss: 0.1542\n",
      "Epoch [5/8], Loss: 0.2001\n",
      "Epoch [6/8], Loss: 0.1229\n",
      "Epoch [7/8], Loss: 0.1183\n",
      "Epoch [8/8], Loss: 0.101\n",
      "Accuracy: 150.00%\n"
     ]
    }
   ],
   "source": [
    "def vectorise_features(data: CharData, pen_weight: float = 1, depth_weight: float = 0.75):\n",
    "    return np.concatenate(\n",
    "        [\n",
    "            data.i_penetration * pen_weight,\n",
    "            data.j_penetration * pen_weight,\n",
    "            data.top_depth * depth_weight,\n",
    "            data.left_depth * depth_weight,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features: list[np.ndarray], labels: list[str]):\n",
    "\n",
    "        labels_transformed = label_encoder.fit_transform(labels)\n",
    "\n",
    "        self.labels = torch.tensor(labels_transformed, dtype=torch.long)\n",
    "\n",
    "        features_array = np.array(features)\n",
    "        self.features = torch.tensor(features_array, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "labels = []\n",
    "features = []\n",
    "\n",
    "for collection in label_collections:\n",
    "    for i in range(len(collection.images)):\n",
    "        labels.append(collection.name)\n",
    "        features.append(vectorise_features(collection.char_data[i]))\n",
    "\n",
    "dataset = Dataset(features, labels)\n",
    "\n",
    "validation_labels = []\n",
    "validation_features = []\n",
    "\n",
    "for collection in validation_label_collections:\n",
    "    for i in range(len(collection.images)):\n",
    "        validation_labels.append(collection.name)\n",
    "        validation_features.append(vectorise_features(collection.char_data[i]))\n",
    "\n",
    "validation_dataset = Dataset(validation_features, validation_labels)\n",
    "\n",
    "class SimpleNN(torch.nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, num_classes: int):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Parameters\n",
    "input_size = 512\n",
    "num_classes = len(label_collections)\n",
    "hidden_size = int(input_size * 2 / 3 + num_classes)\n",
    "num_epochs = 8\n",
    "batch_size = 64\n",
    "\n",
    "print(\"Classes: \", num_classes)\n",
    "print(\"Input size: \", input_size)\n",
    "print(\"Hidden size: \", hidden_size)\n",
    "\n",
    "class Dataloader(torch.utils.data.DataLoader):\n",
    "    def __init__(self, dataset: Dataset, batch_size: int):\n",
    "        super(Dataloader, self).__init__(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "model = SimpleNN(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Pass class weights to the function\n",
    "class_info = []\n",
    "total_samples = 0\n",
    "for class_ in label_encoder.classes_:\n",
    "    col = next((x for x in label_collections if x.name == class_), None)\n",
    "    class_info.append((col.name, len(col.images)))\n",
    "    total_samples += len(col.images)\n",
    "\n",
    "class_weights = []\n",
    "for name, count in class_info:\n",
    "    class_weights.append(total_samples / (num_classes * count))\n",
    "\n",
    "print(\"Classes: \", class_info)\n",
    "print(\"Weights: \", class_weights)\n",
    "\n",
    "labels = []\n",
    "for collection in label_collections:\n",
    "    for i in range(len(collection.images)):\n",
    "        labels.append(collection.name)\n",
    "        \n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights_tensor, reduction='mean')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "dataloader = Dataloader(dataset, batch_size)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_features, batch_labels in dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(batch_features)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "validation_loader = Dataloader(validation_dataset, batch_size)\n",
    "\n",
    "# Initialize lists to store incorrect samples and labels\n",
    "incorrect_samples = []\n",
    "incorrect_true_labels = []\n",
    "incorrect_pred_labels = []\n",
    "\n",
    "# Disable gradient calculation for evaluation\n",
    "with torch.no_grad():\n",
    "    total = 0\n",
    "    for features, labels in validation_loader:\n",
    "        outputs = model(features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += 1\n",
    "        \n",
    "        # Find indices where predictions and labels do not match\n",
    "        incorrect_indices = (predicted != labels).nonzero(as_tuple=True)[0]\n",
    "        # Append incorrect samples and corresponding labels\n",
    "        incorrect_samples.extend(features[incorrect_indices])\n",
    "        incorrect_true_labels.extend(labels[incorrect_indices])\n",
    "        incorrect_pred_labels.extend(predicted[incorrect_indices])       \n",
    "    print(f'Accuracy: {(100 * len(incorrect_samples) / total):.2f}%')\n",
    "\n",
    "# Function to display images\n",
    "def imshow(img, title):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Analyze and display misclassified samples\n",
    "for i in range(min(len(incorrect_samples), 5)):\n",
    "    sample = incorrect_samples[i]\n",
    "    true_label = incorrect_true_labels[i].item()\n",
    "    pred_label = incorrect_pred_labels[i].item()\n",
    "    # imshow(sample.cpu(), f'True: {true_label}, Predicted: {pred_label}')\n",
    "\n",
    "torch.save(model.state_dict(), \"simple_nn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SimpleNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_loaded \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleNN\u001b[49m(input_size, hidden_size, num_classes)\n\u001b[1;32m      3\u001b[0m model_loaded\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimple_nn.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# input_image = cv.imread('./test_data/ma_test2.png')\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# input_image = cv.imread('./test_data/bad_ma.png')\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# input_image = cv.imread('./test_data/nange.png')\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# input_image = cv.imread('./test_data/kha.png')\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# input_image = cv.imread('./test_data/sa_test.png')\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SimpleNN' is not defined"
     ]
    }
   ],
   "source": [
    "model_loaded = SimpleNN(input_size, hidden_size, num_classes)\n",
    "\n",
    "model_loaded.load_state_dict(torch.load(\"simple_nn.pth\", weights_only=True))\n",
    "\n",
    "# input_image = cv.imread('./test_data/ma_test2.png')\n",
    "# input_image = cv.imread('./test_data/bad_ma.png')\n",
    "# input_image = cv.imread('./test_data/nange.png')\n",
    "# input_image = cv.imread('./test_data/kagyi.png')\n",
    "# input_image = cv.imread('./test_data/fat_pha.png')\n",
    "# input_image = cv.imread('./test_data/da_ote.png')\n",
    "# input_image = cv.imread('./test_data/tatalinchate.png')\n",
    "# input_image = cv.imread('./test_data/paaaaaa.png')\n",
    "# input_image = cv.imread('./test_data/cut_ma.png')\n",
    "# input_image = cv.imread('./test_data/kha.png')\n",
    "# input_image = cv.imread('./test_data/sa_test.png')\n",
    "input_image = cv.imread(\"./test_data/ba_test.png\")\n",
    "# input_image = cv.imread(\"./test_data/salein_test.png\")\n",
    "# input_image = cv.imread('./test_data/yakout.png')\n",
    "# input_image = cv.imread(\"./test_data/7.png\")    \n",
    "# input_image = cv.imread(\"./test_data/yag.png\")\n",
    "# input_image = cv.imread(\"./test_data/da.png\")\n",
    "# input_image = cv.imread('./data/မ/ma.png')\n",
    "\n",
    "data = CharData(input_image)\n",
    "\n",
    "data.normalize(5, 5, data.sample_count, data.sample_count)\n",
    "\n",
    "features = vectorise_features(data)\n",
    "\n",
    "features_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "features_tensor = features_tensor.unsqueeze(0)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using CUDA\")\n",
    "    print(\"GPU: \", torch.cuda.get_device_name(0))\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model_loaded.to(device)\n",
    "features_tensor = features_tensor.to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model_loaded(features_tensor)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    confidences = torch.nn.functional.softmax(outputs, dim=1)\n",
    "    print(\n",
    "        f\"Predicted: {label_encoder.inverse_transform(predicted.cpu().numpy())} {predicted.cpu().numpy()}\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nConfidences:\")\n",
    "    for idx, label in enumerate(label_encoder.classes_):\n",
    "        print(f\"{label}: {confidences[0][idx].cpu().numpy():.2f}\")\n",
    "\n",
    "    plt.imshow(input_image)\n",
    "    plt.title(label_encoder.inverse_transform(predicted.cpu().numpy()))\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(f\"Penetration\")\n",
    "    plt.plot(data.i_penetration, label=\"i_penetration\")\n",
    "    plt.plot(data.j_penetration, label=\"j_penetration\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(f\"Depth\")\n",
    "    plt.plot(data.top_depth, label=\"top_depth\")\n",
    "    plt.plot(data.left_depth, label=\"left_depth\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title(\"Features array\")\n",
    "    features_len = len(features)\n",
    "    plt.plot(features)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
